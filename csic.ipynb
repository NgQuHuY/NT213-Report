{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3my31wWSJLr6",
        "outputId": "31101269-97f9-47e7-ec56-a47b9b709a37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Zcr6f73JN5E",
        "outputId": "b9cef08a-808f-41a4-9904-8f353eb534cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/DASANA\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/DASANA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiDcgOXVJK9c"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "import urllib.parse\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IogTtp1XLpeq"
      },
      "outputs": [],
      "source": [
        "from keras import preprocessing\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.layers import Embedding, Dense, Dropout, LSTM, Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeB6sWsyOBgq"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "import csv\n",
        "import random\n",
        "import pandas as pd\n",
        "import re\n",
        "from urllib.parse import unquote\n",
        "\n",
        "data = pd.read_csv('csic_database.csv')\n",
        "X = data[['Method','User-Agent','Pragma','Cache-Control', 'Accept','Accept-encoding','language', 'host', 'cookie', 'content-type', 'connection','lenght', 'content','URL']]\n",
        "y = data['classification']\n",
        "\n",
        "X_string = []\n",
        "cols = X.columns\n",
        "for i in range(len(X)):\n",
        "    temp = ''\n",
        "    for col in cols:\n",
        "        temp += \" \" + str(X.iloc[i][col])\n",
        "    ans = ''\n",
        "    for t in temp:\n",
        "        ans += t\n",
        "\n",
        "    ans =  unquote(ans)\n",
        "\n",
        "    ans = ans.lower()\n",
        "\n",
        "    special_chars = ['/','&','=','+', ';', ',']\n",
        "    for char in special_chars:\n",
        "      ans = ans.replace(char, ' ')\n",
        "\n",
        "\n",
        "    # Xóa các khoảng trắng thừa\n",
        "    ans = ' '.join(ans.split())\n",
        "\n",
        "    X_string.append(ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuZFWuK3Z2ff",
        "outputId": "6801aebd-534a-4e76-ecee-30ac2c06e98f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "get mozilla 5.0 (compatible konqueror 3.5 linux) khtml 3.5.8 (like gecko) no-cache no-cache text xml application xml application xhtml xml text html q 0.9 text plain q 0.8 image png * * q 0.5 x-gzip x-deflate gzip deflate en localhost:8080 jsessionid 3e0d4e5cc38ee9b82904c365bbcb4c88 nan close nan nan http: localhost:8080 tienda1 publico miembros.jsp http 1.1\n"
          ]
        }
      ],
      "source": [
        "print(X_string[154])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7JZ46TPJK9h",
        "outputId": "8f72f3e4-7c8d-4311-deb7-ad9586c678f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "61065\n",
            "92\n",
            "[38 10 11 12 13 14 15 16 17 18 19  6  6  2  1  4  1  4 29  1  2 30  3 31\n",
            "  2 32  3 33 34 35  7  7  3 36 20 21 22 23  9  8 24  5 25  5  5 26  8 37\n",
            " 96 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer(filters = '', num_words = 3000)\n",
        "tokenizer.fit_on_texts(X_string)\n",
        "\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(X_string)\n",
        "pad = pad_sequences(sequences,padding='post')\n",
        "\n",
        "print(len(pad))\n",
        "print(len(pad[1]))\n",
        "print(pad[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu_Z3y1jpERk"
      },
      "outputs": [],
      "source": [
        "def da_sana_algorithm(dataset, sequences, f):\n",
        "\n",
        "    au_dataset = []\n",
        "    L = [len(req) for req in dataset]\n",
        "    L_min = min(L)\n",
        "    L_max = max(L)\n",
        "    mean = (f + 2*f) / 2\n",
        "    stddev = (2*f - f) / 4\n",
        "\n",
        "    for request, Si  in zip(dataset, sequences ):\n",
        "\n",
        "        length = len(request)\n",
        "        L_normalized = (length - L_min) / (L_max - L_min)\n",
        "\n",
        "\n",
        "        Ci = np.random.binomial(1, L_normalized*0.05 ,len(Si))\n",
        "\n",
        "        Ni_Gauss = np.random.normal(mean, stddev, len(Si))\n",
        "        Ni = abs(Ni_Gauss).astype(int)\n",
        "\n",
        "\n",
        "        au_dataset.append(np.array(Si)*(Ci^1) + Ni*Ci)\n",
        "\n",
        "\n",
        "    return au_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xehgcgrfpLXX",
        "outputId": "740f2323-e02e-4a82-8013-6e0adc1ad745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(122130, 92)\n",
            "(122130,)\n",
            "<class 'numpy.int32'>\n",
            "[38 10 11 12 13 14 15 16 17 18 19  6  6  2  1  4  1  4 29  1  2 30  3 31\n",
            "  2 32  3 33 34 35  7  7  3 36 20 21 22 23  9  8 24  5 25  5  5 26  8 37\n",
            " 39 89 61 46 68 67 93 40 61 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ]
        }
      ],
      "source": [
        "au_seq = np.array([*pad, *da_sana_algorithm(X_string,pad,3000)])\n",
        "lable = np.array([*y,*y]).astype(np.int32)\n",
        "\n",
        "print(au_seq.shape)\n",
        "print(lable.shape)\n",
        "print(type(lable[0]))\n",
        "\n",
        "print(au_seq[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Nag7N_4eCb9"
      },
      "outputs": [],
      "source": [
        "labels={'Normal':0, 'Anomalous':1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pngXLPcpcGK",
        "outputId": "ea61c377-af79-458f-b1b1-9ce475a5cd76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 92, 16)            160000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 92, 256)          148480    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 256)              394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 702,977\n",
            "Trainable params: 702,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "287/287 [==============================] - 1244s 4s/step - loss: 0.4341 - accuracy: 0.7807 - val_loss: 0.1541 - val_accuracy: 0.9381\n",
            "Epoch 2/10\n",
            "287/287 [==============================] - 1202s 4s/step - loss: 0.1530 - accuracy: 0.9382 - val_loss: 0.1206 - val_accuracy: 0.9503\n",
            "Epoch 3/10\n",
            "287/287 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9488"
          ]
        }
      ],
      "source": [
        "# split the data into training, validation, and testing sets\n",
        "train_X, test_X, train_y, test_y = train_test_split(au_seq, lable, test_size=0.2, random_state=42)\n",
        "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, test_size=0.25, random_state=42)\n",
        "\n",
        "# size of the vector space in which characters will be embedded\n",
        "embedding_dim = 16\n",
        "max_chars = 10000\n",
        "\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_chars, embedding_dim, input_length=train_X.shape[1]))\n",
        "    model.add(Bidirectional(LSTM(units=128, activation='tanh', dropout=0.5, recurrent_dropout=0.5, return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(units=128, activation='tanh', dropout=0.5, recurrent_dropout=0.5)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "print(model.summary())\n",
        "\n",
        "model.fit(train_X, train_y, epochs=10, batch_size=256, validation_data=(val_X, val_y))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_X, test_y)\n",
        "print(\"Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXwMQpm6n9o8"
      },
      "outputs": [],
      "source": [
        "labels={'Normal':0, 'Anomalous':1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RoaofRQdxDi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(test_X)\n",
        "predicted_labels = [1 if pred > 0.5 else 0 for pred in predictions]\n",
        "\n",
        "print(classification_report(test_y, predicted_labels, target_names=labels))\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(test_y, predicted_labels, display_labels= labels, xticks_rotation = 'vertical')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}